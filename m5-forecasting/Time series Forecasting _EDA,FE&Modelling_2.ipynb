{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly.subplots import make_subplots\n",
    "import gc\n",
    "import joblib\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df.pickle','rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Engineering\n",
    "Time Series data must be re-framed as a supervised learning dataset before we can start using machine learning algorithms.\n",
    "\n",
    "There is no concept of input and output features in time series. Instead, we must choose the variable to be predicted and use feature engineering to construct all of the inputs that will be used to make predictions for future time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of feature engineering is to provide strong and ideally simple relationships between new input features and the output feature for the supervised learning algorithm to model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Label Encoding</h5>\n",
    "1. Remove unwanted data to create space in RAM for further processing.<br>\n",
    "2. Label Encode categorical features.(I had converted already converted categorical variable to category type. So, I can simply use their codes instead of using LableEncoder)<br>\n",
    "3. Remove date as its features are already present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note:\n",
    "I'm storing the categories correponding to their respective category codes so that I'can use them later on while making the submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개수 많을 때 dict형태로 정리하기! :https://cnpnote.tistory.com/entry/PYTHON-%ED%8C%90%EB%8B%A4-Pandas-%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EB%A5%BC-%EC%88%AB%EC%9E%90%EB%A1%9C-%EB%B3%80%ED%99%98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60034810 entries, 0 to 60034809\n",
      "Data columns (total 23 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            category      \n",
      " 1   item_id       category      \n",
      " 2   dept_id       category      \n",
      " 3   cat_id        category      \n",
      " 4   store_id      category      \n",
      " 5   state_id      category      \n",
      " 6   d             object        \n",
      " 7   sold          int16         \n",
      " 8   date          datetime64[ns]\n",
      " 9   wm_yr_wk      int16         \n",
      " 10  weekday       category      \n",
      " 11  wday          int8          \n",
      " 12  month         int8          \n",
      " 13  year          int16         \n",
      " 14  event_name_1  category      \n",
      " 15  event_type_1  category      \n",
      " 16  event_name_2  category      \n",
      " 17  event_type_2  category      \n",
      " 18  snap_CA       int8          \n",
      " 19  snap_TX       int8          \n",
      " 20  snap_WI       int8          \n",
      " 21  sell_price    float16       \n",
      " 22  revenue       float32       \n",
      "dtypes: category(11), datetime64[ns](1), float16(1), float32(1), int16(3), int8(5), object(1)\n",
      "memory usage: 3.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sam=df.sample(frac = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18010443, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18010443 entries, 940455 to 24105304\n",
      "Data columns (total 23 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            category      \n",
      " 1   item_id       category      \n",
      " 2   dept_id       category      \n",
      " 3   cat_id        category      \n",
      " 4   store_id      category      \n",
      " 5   state_id      category      \n",
      " 6   d             object        \n",
      " 7   sold          int16         \n",
      " 8   date          datetime64[ns]\n",
      " 9   wm_yr_wk      int16         \n",
      " 10  weekday       category      \n",
      " 11  wday          int8          \n",
      " 12  month         int8          \n",
      " 13  year          int16         \n",
      " 14  event_name_1  category      \n",
      " 15  event_type_1  category      \n",
      " 16  event_name_2  category      \n",
      " 17  event_type_2  category      \n",
      " 18  snap_CA       int8          \n",
      " 19  snap_TX       int8          \n",
      " 20  snap_WI       int8          \n",
      " 21  sell_price    float16       \n",
      " 22  revenue       float32       \n",
      "dtypes: category(11), datetime64[ns](1), float16(1), float32(1), int16(3), int8(5), object(1)\n",
      "memory usage: 929.1+ MB\n",
      "Wall time: 412 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sam.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "df_sam.id = df_sam.id.astype('category')\n",
    "df_sam.item_id = df_sam.item_id.astype('category')\n",
    "df_sam.dept_id = df_sam.dept_id.astype('category')\n",
    "df_sam.cat_id = df_sam.cat_id.astype('category')\n",
    "df_sam.store_id = df_sam.store_id.astype('category')\n",
    "df_sam.state_id = df_sam.state_id.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Store the categories along with their codes - 개수 많을 때 dict형태로 정리하기!\n",
    "d_sam_id = dict(zip(df_sam.id.cat.codes,df_sam.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sam_item_id = dict(zip(df_sam.item_id.cat.codes,df_sam.item_id))\n",
    "d_sam_dept_id = dict(zip(df_sam.dept_id.cat.codes,df_sam.dept_id))\n",
    "d_sam_cat_id = dict(zip(df_sam.cat_id.cat.codes,df_sam.cat_id))\n",
    "d_sam_store_id = dict(zip(df_sam.store_id.cat.codes,df_sam.store_id))\n",
    "d_sam_state_id = dict(zip(df_sam.state_id.cat.codes,df_sam.state_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 \n",
    "#del group, group_price_cat,group_price_store,group_state,group_state_store,cal_data\n",
    "#gc.collect()\n",
    "\n",
    "#2\n",
    "df_sam.d = df_sam['d'].apply(lambda x : str(x).split('_')[1]).astype(np.int16)\n",
    "cols = df_sam.dtypes.index.tolist()\n",
    "types = df_sam.dtypes.values.tolist()\n",
    "for i,type in enumerate(types):\n",
    "    if type.name == 'category':\n",
    "        df_sam[cols[i]] = df_sam[cols[i]].cat.codes\n",
    "        \n",
    "        \n",
    "# 3\n",
    "df_sam.drop('date',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Introduce Lags\n",
    "Lag features are the classical way that time series forecasting problems are transformed into supervised learning problems.\n",
    "\n",
    "Introduce lags to the the target variable sold. The maximum lag I have introduced is 36 days. It's purely upto you how many lags you want to introduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Introduce lags\n",
    "lags = [1,2,3,6,12,24,36]\n",
    "for lag in lags:\n",
    "    df['sold_lag_'+str(lag)] = df.groupby(['id','item_id','dept_id','cat_id','store_id','state_id'],as_index = False)['sold'].shift(lag).astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Mean Encoding\n",
    "From a mathematical point of view, mean encoding represents a probability of your target variable, conditional on each value of the feature. In a way, it embodies the target variable in its encoded value. I have calculated mean encodings on the basis of following logical features I could think of:-\n",
    "\n",
    "- item\n",
    "- state\n",
    "- store\n",
    "- category\n",
    "- department\n",
    "- category & department\n",
    "- store & item\n",
    "- category & item\n",
    "- department & item\n",
    "- state & store\n",
    "- state, store and category\n",
    "- store, category and department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sam['iteam_sold_avg'] = df_sam.groupby('item_id')['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['state_sold_avg'] = df_sam.groupby('state_id')['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['store_sold_avg'] = df_sam.groupby('store_id')['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['cat_sold_avg'] = df_sam.groupby('cat_id')['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['dept_sold_avg'] = df_sam.groupby('dept_id')['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['cat_dept_sold_avg'] = df_sam.groupby(['cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['store_item_sold_avg'] = df_sam.groupby(['store_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['cat_item_sold_avg'] = df_sam.groupby(['cat_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['dept_item_sold_avg'] = df_sam.groupby(['dept_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['state_store_sold_avg'] = df_sam.groupby(['state_id','store_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['state_store_cat_sold_avg'] = df_sam.groupby(['state_id','store_id','cat_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['store_cat_dept_sold_avg'] = df_sam.groupby(['store_id','cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sold</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>store_sold_avg</th>\n",
       "      <th>cat_sold_avg</th>\n",
       "      <th>dept_sold_avg</th>\n",
       "      <th>cat_dept_sold_avg</th>\n",
       "      <th>store_item_sold_avg</th>\n",
       "      <th>cat_item_sold_avg</th>\n",
       "      <th>dept_item_sold_avg</th>\n",
       "      <th>state_store_sold_avg</th>\n",
       "      <th>state_store_cat_sold_avg</th>\n",
       "      <th>store_cat_dept_sold_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>940455</th>\n",
       "      <td>28008</td>\n",
       "      <td>2800</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>11105</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.117188</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>0.300293</td>\n",
       "      <td>0.300293</td>\n",
       "      <td>0.171143</td>\n",
       "      <td>0.284424</td>\n",
       "      <td>0.284424</td>\n",
       "      <td>1.117188</td>\n",
       "      <td>0.698730</td>\n",
       "      <td>0.192139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45300362</th>\n",
       "      <td>28067</td>\n",
       "      <td>2806</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1486</td>\n",
       "      <td>0</td>\n",
       "      <td>11504</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875977</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>0.300293</td>\n",
       "      <td>0.300293</td>\n",
       "      <td>0.159180</td>\n",
       "      <td>0.119324</td>\n",
       "      <td>0.119324</td>\n",
       "      <td>0.875977</td>\n",
       "      <td>0.520996</td>\n",
       "      <td>0.233521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27065154</th>\n",
       "      <td>6186</td>\n",
       "      <td>618</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>888</td>\n",
       "      <td>0</td>\n",
       "      <td>11323</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036133</td>\n",
       "      <td>1.624023</td>\n",
       "      <td>2.035156</td>\n",
       "      <td>2.035156</td>\n",
       "      <td>0.743164</td>\n",
       "      <td>0.793457</td>\n",
       "      <td>0.793457</td>\n",
       "      <td>1.036133</td>\n",
       "      <td>1.500977</td>\n",
       "      <td>1.893555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17912770</th>\n",
       "      <td>13324</td>\n",
       "      <td>1332</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>0</td>\n",
       "      <td>11232</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949219</td>\n",
       "      <td>1.624023</td>\n",
       "      <td>2.035156</td>\n",
       "      <td>2.035156</td>\n",
       "      <td>0.427246</td>\n",
       "      <td>1.180664</td>\n",
       "      <td>1.180664</td>\n",
       "      <td>0.949219</td>\n",
       "      <td>1.356445</td>\n",
       "      <td>1.739258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31079999</th>\n",
       "      <td>29793</td>\n",
       "      <td>2979</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1020</td>\n",
       "      <td>1</td>\n",
       "      <td>11342</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>0.300293</td>\n",
       "      <td>0.300293</td>\n",
       "      <td>0.284180</td>\n",
       "      <td>0.808105</td>\n",
       "      <td>0.808105</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.356689</td>\n",
       "      <td>0.190430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  item_id  dept_id  cat_id  store_id  state_id     d  sold  \\\n",
       "940455    28008     2800        6       2         8         2    31     0   \n",
       "45300362  28067     2806        6       2         7         2  1486     0   \n",
       "27065154   6186      618        2       0         6         1   888     0   \n",
       "17912770  13324     1332        2       0         4         1   588     0   \n",
       "31079999  29793     2979        6       2         3         0  1020     1   \n",
       "\n",
       "          wm_yr_wk  weekday  ...  store_sold_avg  cat_sold_avg  dept_sold_avg  \\\n",
       "940455       11105        1  ...        1.117188      0.716797       0.300293   \n",
       "45300362     11504        3  ...        0.875977      0.716797       0.300293   \n",
       "27065154     11323        4  ...        1.036133      1.624023       2.035156   \n",
       "17912770     11232        0  ...        0.949219      1.624023       2.035156   \n",
       "31079999     11342        6  ...        0.695801      0.716797       0.300293   \n",
       "\n",
       "          cat_dept_sold_avg  store_item_sold_avg  cat_item_sold_avg  \\\n",
       "940455             0.300293             0.171143           0.284424   \n",
       "45300362           0.300293             0.159180           0.119324   \n",
       "27065154           2.035156             0.743164           0.793457   \n",
       "17912770           2.035156             0.427246           1.180664   \n",
       "31079999           0.300293             0.284180           0.808105   \n",
       "\n",
       "          dept_item_sold_avg  state_store_sold_avg  state_store_cat_sold_avg  \\\n",
       "940455              0.284424              1.117188                  0.698730   \n",
       "45300362            0.119324              0.875977                  0.520996   \n",
       "27065154            0.793457              1.036133                  1.500977   \n",
       "17912770            1.180664              0.949219                  1.356445   \n",
       "31079999            0.808105              0.695801                  0.356689   \n",
       "\n",
       "          store_cat_dept_sold_avg  \n",
       "940455                   0.192139  \n",
       "45300362                 0.233521  \n",
       "27065154                 1.893555  \n",
       "17912770                 1.739258  \n",
       "31079999                 0.190430  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Rolling Window Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is called the rolling window method because the window would be different for every data point.\n",
    "\n",
    "I'll be calculating weekly rolling avearge of the items sold. More features like rolling min, max or sum can also be calculated. Also, same features can be calculated for revenue as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sam['rolling_sold_mean'] = df_sam.groupby(['id','item_id','dept_id','cat_id','store_id','state_id'])['sold'].transform(lambda x : x.rolling(window =7).mean()).astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Expanding Window Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply an advanced version of the rolling window technique. In the case of a rolling window, the size of the window is constant while the window slides as we move forward in time. Hence, we consider only the most recent values and ignore the past values. Here’s a gif that explains how our expanding window function works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be calculating expanding avearge of the items sold. More features like expanding min, max or sum can also be calculated. Also, same features can be calculated for revenue as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sam['expanding_sold_mean'] = df_sam.groupby(['id','item_id','dept_id','cat_id','store_id','state_id'])['sold'].transform(lambda x : x.expanding(2).mean()).astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Trends\n",
    "\n",
    "I will be creating a selling trend feature, which will be some positive value if the daily items sold are greater than the entire duration average ( d_1 - d_1969 ) else negative. More trend features can be added but I'll only add this one to keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sam['daily_avg_sold'] = df_sam.groupby(['id','item_id','dept_id','cat_id','store_id','state_id','d'])['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['avg_sold'] = df.groupby(['id','item_id','dept_id','cat_id','store_id','state_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df_sam['selling_trend'] = (df_sam['daily_avg_sold'] - df_sam['avg_sold']).astype(np.float16)\n",
    "df_sam.drop(['daily_avg_sold','avg_sold'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Save the data\n",
    "\n",
    "Now since all the new features are created, let's save the data so that it can be trained separately.Also, lags introduce a lot of Null values, so I'll remove data for first 35 days as I have introduced lags till 36 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sam = df_sam[df_sam['d']>=36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17690827 entries, 45300362 to 24105304\n",
      "Data columns (total 37 columns):\n",
      " #   Column                    Dtype  \n",
      "---  ------                    -----  \n",
      " 0   id                        int16  \n",
      " 1   item_id                   int16  \n",
      " 2   dept_id                   int8   \n",
      " 3   cat_id                    int8   \n",
      " 4   store_id                  int8   \n",
      " 5   state_id                  int8   \n",
      " 6   d                         int16  \n",
      " 7   sold                      int16  \n",
      " 8   wm_yr_wk                  int16  \n",
      " 9   weekday                   int8   \n",
      " 10  wday                      int8   \n",
      " 11  month                     int8   \n",
      " 12  year                      int16  \n",
      " 13  event_name_1              int8   \n",
      " 14  event_type_1              int8   \n",
      " 15  event_name_2              int8   \n",
      " 16  event_type_2              int8   \n",
      " 17  snap_CA                   int8   \n",
      " 18  snap_TX                   int8   \n",
      " 19  snap_WI                   int8   \n",
      " 20  sell_price                float16\n",
      " 21  revenue                   float32\n",
      " 22  iteam_sold_avg            float16\n",
      " 23  state_sold_avg            float16\n",
      " 24  store_sold_avg            float16\n",
      " 25  cat_sold_avg              float16\n",
      " 26  dept_sold_avg             float16\n",
      " 27  cat_dept_sold_avg         float16\n",
      " 28  store_item_sold_avg       float16\n",
      " 29  cat_item_sold_avg         float16\n",
      " 30  dept_item_sold_avg        float16\n",
      " 31  state_store_sold_avg      float16\n",
      " 32  state_store_cat_sold_avg  float16\n",
      " 33  store_cat_dept_sold_avg   float16\n",
      " 34  rolling_sold_mean         float16\n",
      " 35  expanding_sold_mean       float16\n",
      " 36  selling_trend             float16\n",
      "dtypes: float16(16), float32(1), int16(6), int8(14)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "df_sam.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sam.to_csv('Input/data_sam.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
